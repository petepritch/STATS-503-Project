{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libs ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "import io\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Personal Smoking Habits\n",
    "questionnaire_url_18 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2017-2018/P_SMQ.XPT'\n",
    "questionnaire_url_16 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2015-2016/SMQ_I.XPT'\n",
    "questionnaire_url_14 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2013-2014/SMQ_H.XPT'\n",
    "questionnaire_url_12 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2011-2012/SMQ_G.XPT'\n",
    "questionnaire_url_10 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2009-2010/SMQ_F.XPT'\n",
    "questionnaire_url_8  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2007-2008/SMQ_E.XPT'\n",
    "questionnaire_url_6  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2005-2006/SMQ_D.XPT'\n",
    "questionnaire_url_4  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2003-2004/SMQ_C.XPT'\n",
    "questionnaire_url_2  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2001-2002/SMQ_B.XPT'\n",
    "questionnaire_url_0  = 'https://wwwn.cdc.gov//Nchs/Nhanes/1999-2000/SMQ.XPT'\n",
    "\n",
    "#Second Hand smoke Exposure\n",
    "shs_questionnaire_url_18 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2017-2018/P_SMQFAM.XPT'\n",
    "shs_questionnaire_url_16 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2015-2016/SMQFAM_I.XPT'\n",
    "shs_questionnaire_url_14 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2013-2014/SMQFAM_H.XPT'\n",
    "shs_questionnaire_url_12 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2011-2012/SMQFAM_G.XPT'\n",
    "shs_questionnaire_url_10 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2009-2010/SMQFAM_F.XPT'\n",
    "shs_questionnaire_url_8  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2007-2008/SMQFAM_E.XPT'\n",
    "shs_questionnaire_url_6  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2005-2006/SMQFAM_D.XPT'\n",
    "shs_questionnaire_url_4  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2003-2004/SMQFAM_C.XPT'\n",
    "shs_questionnaire_url_2  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2001-2002/SMQFAM_B.XPT'\n",
    "shs_questionnaire_url_0  = 'https://wwwn.cdc.gov//Nchs/Nhanes/1999-2000/SMQFAM.XPT'\n",
    "\n",
    "\n",
    "#VOC levels\n",
    "voc_url_18 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2017-2018/P_VOCWB.XPT'\n",
    "voc_url_16 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2015-2016/VOCWB_I.XPT'\n",
    "voc_url_14 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2013-2014/VOCWB_H.XPT'\n",
    "voc_url_12 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2011-2012/VOCWB_G.XPT'\n",
    "voc_url_10 = 'https://wwwn.cdc.gov//Nchs/Nhanes/2009-2010/VOCWB_F.XPT'\n",
    "voc_url_8  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2007-2008/VOCWB_E.XPT'\n",
    "voc_url_6  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2005-2006/VOCWB_D.XPT'\n",
    "voc_url_4  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2003-2004/L04VOC_C.XPT'\n",
    "voc_url_2  = 'https://wwwn.cdc.gov//Nchs/Nhanes/2001-2002/L04VOC_B.XPT'\n",
    "voc_url_0  = 'https://wwwn.cdc.gov//Nchs/Nhanes/1999-2000/LAB04.XPT'\n",
    "\n",
    "urls_2013 = [(shs_questionnaire_url_0, questionnaire_url_0, voc_url_0),(shs_questionnaire_url_2, questionnaire_url_2, voc_url_2),(shs_questionnaire_url_4, questionnaire_url_4, voc_url_4),\n",
    "        (shs_questionnaire_url_6, questionnaire_url_6, voc_url_6),(shs_questionnaire_url_8, questionnaire_url_8, voc_url_8),(shs_questionnaire_url_10, questionnaire_url_10, voc_url_10),\n",
    "        (shs_questionnaire_url_12, questionnaire_url_12, voc_url_12)]\n",
    "\n",
    "urls_2014 = [(shs_questionnaire_url_14, questionnaire_url_14, voc_url_14),(shs_questionnaire_url_16, questionnaire_url_16, voc_url_16),\n",
    "        (shs_questionnaire_url_18,questionnaire_url_18, voc_url_18)]\n",
    "\n",
    "\n",
    "def read_sas_url(url):\n",
    "    r = requests.get(url)\n",
    "    return pd.read_sas(io.BytesIO(r.content), format= 'xport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_data(urls, predictors_list, response_var_d, response_var_sh):\n",
    "\n",
    "    \"\"\"\n",
    "    This function requests a list of similar datasets from the cdc website\n",
    "\n",
    "    urls: The url to the dataset\n",
    "    predictor_list : the lsit of variables to be pulled from the dataset\n",
    "    response_var_d: the response variable to be pulled from the direct smoking habits questionaire\n",
    "    response_var_sh: the response variable to be pulled from the second hand smoke exposure questionaire\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "\n",
    "    for url_sh, url_d, url_X in urls:\n",
    "\n",
    "        print(f\"Fetching Data for Year: {url_X[34:43] }\")\n",
    "        \n",
    "        X = read_sas_url(url_X)\n",
    "        d = read_sas_url(url_d)\n",
    "        sh = read_sas_url(url_sh)\n",
    "\n",
    "        Data_year = pd.merge(pd.merge(X, d, on = ['SEQN']), sh, on = ['SEQN'])[predictors_list + [response_var_d, response_var_sh]]\n",
    "\n",
    "        all_dfs.append(Data_year)\n",
    "    \n",
    "    Data_Xy = pd.concat(all_dfs)\n",
    "    Data_Xy= Data_Xy.dropna().reindex()\n",
    "    Data_Xy[response_var_d] = Data_Xy[response_var_d].astype(int)-1 \n",
    "    Data_Xy[response_var_sh] = Data_Xy[response_var_sh].astype(int)\n",
    "\n",
    "    return Data_Xy\n",
    "\n",
    "def fetch_data(urls1, urls2, predictors_list, response1, response13, response14, save = False):\n",
    "\n",
    "    \"\"\"\n",
    "    This function requests a Multiplte datasets from the cdc website: \n",
    "    this function is necessariy because datasets can have different variables/names with the same data\n",
    "    Functionally, it just calls request_data and combines the frames.\n",
    "    \"\"\"\n",
    "\n",
    "    df1 = request_data(urls1, predictors_list, response1, response13)\n",
    "    df2 = request_data(urls2, predictors_list, response1, response14)\n",
    "    Data_Xy = pd.concat([df1, df2])\n",
    "\n",
    "    if save == True:\n",
    "        #You have to put the path you want to save the frame to here\n",
    "        Data_Xy.to_csv('/Users/omarafifi/Downloads/NHANES Project/data/NHANES.csv')\n",
    "        print('Data Copied into Local Directory.')\n",
    "        \n",
    "    print(\"Data Load Complete.\")\n",
    "\n",
    "    return Data_Xy\n",
    "\n",
    "def append_match(datasets, keep_cols):\n",
    "    \"\"\" \n",
    "    This function takes a list of datasets and concats\n",
    "    them while matching the column names. \n",
    "    \"\"\"\n",
    "\n",
    "    if not datasets or len(datasets) == 0:\n",
    "        return None\n",
    "\n",
    "    # Reove columns not in list for each data set\n",
    "    filtered_datasets = [df[keep_cols] for df in datasets]\n",
    "\n",
    "    # Extract common col names\n",
    "    common_cols = filtered_datasets[0].columns\n",
    "\n",
    "    # Check if all datasets have same cols\n",
    "    for df in filtered_datasets[1:]:\n",
    "        common_cols = common_cols.intersection(df.columns)\n",
    "\n",
    "    # Concat all the datasets if assumptions are met\n",
    "    append_df = pd.concat([df[common_cols] for df in filtered_datasets], ignore_index=True)\n",
    "\n",
    "    return append_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some of the respone formatting is inconsistent ... this reformats things. \n",
    "def relable(df):\n",
    "\n",
    "    \"\"\"\n",
    "    The response variables for second hand smokers and direct smokers are different [0,1,2] vs [1,0]. \n",
    "    This function converts them so that they index from 0. \n",
    "    \"\"\"\n",
    "\n",
    "    data = df.copy()\n",
    "\n",
    "    data['SMD460']+= 1\n",
    "    data['SMD460'] = data['SMD460'].fillna(0)\n",
    "    data = data[data['SMD460'] < 10]\n",
    "\n",
    "    data['SMD460'] = (data['SMD460'] > 1).astype(int)\n",
    "\n",
    "\n",
    "    data['SMD410'] = data['SMD410'].fillna(0)\n",
    "    data = data[data['SMD410'] < 3]\n",
    "    data['SMD410'] = (data['SMD410'] == 1).astype(int)\n",
    "\n",
    "\n",
    "    data['SH EXP']  = data['SMD460'] + data['SMD410']\n",
    "    data = data.drop(['SMD410','SMD460'], axis = 1)\n",
    "\n",
    "    #1 if the person smokes\n",
    "    data['SMOKE'] = (data['SMQ040']<2).astype(int)\n",
    "\n",
    "    return data.drop(['SMQ040'], axis = 1)\n",
    "\n",
    "def process(df, transform = False, combine_columns = True):\n",
    "\n",
    "    \"\"\"This applies a log transformation to the predictors and combines the response variables int0 a single response\n",
    "    transform: if the log transformation should be applied\n",
    "    combine_columns: if the responses should be combines: this should only be false if you want to partition the data by response groups.\n",
    "    \"\"\"\n",
    "\n",
    "    data = df.copy()\n",
    "    data = relable(data)\n",
    "\n",
    "    #people who are not exposed to tobacco at all\n",
    "    non_smokers = data[data['SMOKE'] == 0]\n",
    "    non_smokers = non_smokers[non_smokers['SH EXP'] == 0]\n",
    "    #people exposed to smoke, but who do not smoke\n",
    "    sh_smokers = data[data['SMOKE'] == 0]\n",
    "    sh_smokers = sh_smokers[sh_smokers['SH EXP'] == 1]\n",
    "\n",
    "    smokers = data[data['SMOKE'] == 1]\n",
    "\n",
    "    data = pd.concat([non_smokers, sh_smokers, smokers])\n",
    "\n",
    "    if combine_columns: # make a single response variable: 0,1,2 \n",
    "            data['SMOKE'] = data['SMOKE']+ data['SH EXP']\n",
    "            data = data.drop(['SH EXP'], axis = 1)\n",
    "\n",
    "    #take the log transformation\n",
    "    if transform == True:\n",
    "        data['LBXVBZ'] = np.log(data['LBXVBZ'])\n",
    "        data['LBXVEB'] = np.log(data['LBXVEB'])\n",
    "        data['LBXVXY'] = np.log(data['LBXVXY'])\n",
    "    \n",
    "    #reshuffle\n",
    "    return data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_list = ['LBXVBZ','LBXVEB','LBXVXY']\n",
    "response_var_d = 'SMQ040'\n",
    "response_var_sh_2013 = 'SMD410'\n",
    "response_var_sh_2014 = 'SMD460'\n",
    "\n",
    "#transformed and seperate responses (i.e. one columns for secod hand exposure, and one columns for whether or not they smoke)\n",
    "nhanes_log_sc= process(fetch_data(urls_2013, urls_2014, predictors_list, \n",
    "                                              response_var_d, response_var_sh_2013, \n",
    "                                              response_var_sh_2014, save = False), \n",
    "                                              transform= True, combine_columns=False)\n",
    "#transformed with combined responses : this is the frame that gets used for prediction\n",
    "nhanes_log__cc = process(fetch_data(urls_2013, urls_2014, predictors_list, \n",
    "                                              response_var_d, response_var_sh_2013, \n",
    "                                              response_var_sh_2014, save = False), \n",
    "                                              transform= True, combine_columns=True)\n",
    "#untransfored and seperate repsonses\n",
    "nhanes_no_log_sc = process(fetch_data(urls_2013, urls_2014, predictors_list, \n",
    "                                              response_var_d, response_var_sh_2013, \n",
    "                                              response_var_sh_2014, save = False), \n",
    "                                              transform= False, combine_columns=False)\n",
    "#untransformed with combined responses.\n",
    "nhanes_no_log_cc = process(fetch_data(urls_2013, urls_2014, predictors_list, \n",
    "                                              response_var_d, response_var_sh_2013, \n",
    "                                              response_var_sh_2014, save = False), \n",
    "                                              transform= False, combine_columns=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(nhanes_log__cc.drop(['SMOKE'], axis = 1), nhanes_log__cc['SMOKE'])\n",
    "\n",
    "pipe = Pipeline(steps = [('scale',StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__criterion': ['gini', 'entropy'],\n",
    "    'clf__max_depth': [None, 5, 10],\n",
    "    'clf__min_samples_split': [2, 5, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, verbose=3)\n",
    "pipe.fit(X_train[:200], y_train[:200])\n",
    "pipe.score(X_test, y_test)\n",
    "grid.fit(X_train, y_train)\n",
    "dt_mod = grid.best_estimator_\n",
    "print(classification_report(dt_mod.predict(X_test), y_test))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_test, dt_mod.predict(X_test), labels=dt_mod.classes_),\n",
    "                              display_labels=dt_mod.classes_)\n",
    "disp.plot()\n",
    "plt.title('Classification Tree Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = dt_mod.named_steps['clf']\n",
    "\n",
    "new_cols = ['Benzene', 'Ethylbenzene', 'Xylene']\n",
    "\n",
    "plt.barh(new_cols, \n",
    "        width = np.sort(rf.feature_importances_),\n",
    "        color = [\"#F9EAF9\",\"#E1C2E1\",\"#C8AAC8\",\"#AB90AB\",\"#917A91\",\"#6C596C\"], \n",
    "        edgecolor = \"#413E41\")\n",
    "plt.title(\"Classification Tree Feature Importance Plot\")\n",
    "plt.xlabel(\"Avg. Decrease in Impurity\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
